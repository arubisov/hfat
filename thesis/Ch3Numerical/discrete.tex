\section{Discrete Time}
We now consider the same optimization problem but in discrete time, and we will attempt to reuse the same variable definitions and notation where it makes sense; namely, the constants $\Delta_{t_{I}}, \Delta_{t_{S}}, \#_{bins}, \xi$ are defined as before. We will be analysing the embedded discrete time Markov chain, which for any time interval of size $
\Delta t$ can be obtained from the CTMC by considering the transition probability matrix obtained by $\mat{P} = e^{\mat{G}\Delta t}$. We have derived the below results with the consideration that $\Delta t = \Delta_{t_{I}} = \Delta_{t_{S}} = 1000ms$, though this is not strictly necessary. For convenience, we relist in discrete-time form the processes we will consider for this control problem:

\setlength{\LTpost}{0pt}
\begin{longtable}{ll}
Imbalance & $\rho_k$ \\
\multicolumn{2}{@{\qquad}p{\linewidth-2em}}{The finite, discrete stochastic process that results from sorting $I(t)$ into $\{1, \dots, \#_{bins} \}$, and which evolves in accordance with the Markov chain $\bz$.}  \vspace{6pt} \\ 
Midprice & $S_k$ \\
\multicolumn{2}{@{\qquad}p{\linewidth-2em}}{A stochastic process that evolves in accordance with the Markov chain $\bz$.}  \vspace{6pt} \\ 
Midprice Change & $\Delta S_k = \sgn(S_k - S_{k-1})$  \vspace{6pt} \\ 
Imbalance \& Midprice Change & $\bz_k = (\rho_k, \Delta S_k)$ \\
\multicolumn{2}{@{\qquad}p{\linewidth-2em}}{A discrete-time 2-dimensional time-homogenous Markov chain with transition probabilities $\bP_{ij}$.} \vspace{6pt} \\ 
$\Delta S$ when LOB Shuffles & $\{ \eta_{0,\bz}, \eta_{1,\bz}, \dots \} \sim F_{\bz}$ \\
\multicolumn{2}{@{\qquad}p{\linewidth-2em}}{i.i.d. random variables, where the distribution is dependent on the Markov chain state. This is the price change that accompanies a change in Markov chain state.} \vspace{6pt} \\ 
Other Agent Market Orders & $K^{\pm}_k$ \\
\multicolumn{2}{@{\qquad}p{\linewidth-2em}}{The sum of the Poisson process with rate $\mu^{\pm}(\bz_k)$ over the past time interval $\Delta t$. This allows us to consider a continuous time process in discrete time by looking at how many arrivals there were since the previous timestep. $K^+$ represents the arrival of other agents' buy market orders.} \vspace{6pt} \\ 
Our Limit Order Posting Depth & $\delta^{\pm}_k$ \\
\multicolumn{2}{@{\qquad}p{\linewidth-2em}}{One of the $\cF$-predictable processes that we will control. The value of $\delta^+$ dictates how deep on the buy side we will post our buy limit order - if $\delta^+ = 0$ then we are posting at-the-touch.}  \vspace{6pt} \\ 
Our LO fill count & $L^{\pm}_k$ \\
\multicolumn{2}{@{\qquad}p{\linewidth-2em}}{A binary random processes (not Poisson) identifying whether our buy ($L^+$) or sell ($L^-$) limit orders were filled. This process is considered in greater detail later in this section.}  \vspace{6pt} \\ 
Our MOs & $M^{\pm}_k$ \\
\multicolumn{2}{@{\qquad}p{\linewidth-2em}}{Our other controlled process. $M^+$ represents our executing a buy market order. In executing market orders, we assume that the size of the MOs is small enough to achieve the best bid/ask price, and not walk the book.}  \vspace{6pt} \\ 
Cash & $X^{\btau, \delta}_k$ \\
\multicolumn{2}{@{\qquad}p{\linewidth-2em}}{A stochastic variable representing our cash, initially zero.}  \vspace{6pt} \\ 
Inventory & $Q^{\btau, \delta}_k$ \\
\multicolumn{2}{@{\qquad}p{\linewidth-2em}}{A stochastic process representing our assets, initially zero.}
\end{longtable}

As per a typical discrete-time stochastic control problem, we will consider the following state, control, and random vectors: 

\begin{tabular}{rl}
\multirow{4}{*}{State $\vec{x}_{k} = \begin{pmatrix}
x_k \\
s_k \\
\bz_k \\
q_k 
\end{pmatrix}$} & cash \\
& stock price \\
& Markov chain state, as above \\
& inventory \\[4ex]
\multirow{4}{*}{Control $\vec{u}_{k} = \begin{pmatrix}
\delta_k^+ \\
\delta_k^- \\
M_k^+ \\
M_k^-
\end{pmatrix}$} & bid posting depth \\
& ask posting depth \\
& buy MO - binary control \\
& sell MO - binary control \\[4ex]
\multirow{3}{*}{
Random $\vec{w}_{k} = \begin{pmatrix}
K_k^+ \\
K_k^- \\
\omega_k
\end{pmatrix}$}
& other agent buy MOs - binary \\
& other agent sell MOs - binary \\
& random variable uniformly distributed on [0,1]
\end{tabular}

Following \cite{Kwong15}, we'll write the evolution of the Markov chain as a function of the current state and a uniformly distributed random variable $\omega$:
\begin{equation}
\bz_{k+1} = T(\bz_k, \omega_k) = \sum_{i=0}^{|\Gamma|} i \cdot \indicator_{\left( \sum_{j=0}^{i-1} \bP_{\bz_k,j} , \sum_{j=0}^{i} \bP_{\bz_k,j} \right]} (\omega_k)
\end{equation}
Here $\indicator_A(\omega) = \begin{cases} 1 & \text{if } \omega \in A \\
0 & \text{if } \omega \not\in A
\end{cases}$, and hence $Z_{k+1}$ is assigned to the value $i$ for which $\omega_k$ is in the indicated interval of probabilities.

Our Markovian state evolution function $f$, given by $\vec{x}_{k+1} = f \left( \vec{x}_{k},\vec{u}_{k}, \vec{w}_{k} \right)$, can be written explicitly as
\begin{equation}\label{eq:discretestateevolution}
\begin{pmatrix}
x_{k+1} \\
s_{k+1} \\
\bz_{k+1} \\
q_{k+1} 
\end{pmatrix} = \begin{pmatrix}
x_k \\
s_{k} + \eta_{k+1,T(\bz_k, \omega_k)} \\
T(\bz_k, \omega_k) \\
q_{k}
\end{pmatrix}
+ \begin{pmatrix}
s_k + \xi + \delta_k^- \\
0 \\
0 \\
-1
\end{pmatrix}L_k^-
+ \begin{pmatrix}
- (s_k - \xi - \delta_k^+) \\
0 \\
0 \\
1
\end{pmatrix} L_k^+
\end{equation}
The cash process at a subsequent timestep is equal to the cash at the previous step, plus the profits and costs of executing market and/or limit orders. At time $k$, if the agent posts a sell limit order that gets filled ``between timesteps'' $k$ and $k+1$ (depending on the binary random variable $L_k^-$, itself depending on the binary random variable $K_k^+$), the revenue depends on the stock price at $k$. This is consistent with reality as with backtesting: while we are choosing to model the posting \textit{depth}, in reality a submitted limit order has a specific price specified - thus once the order is submitted at $k$, the potential cash received is fixed. 

Our impulse control at every time step is given by
\begin{equation}\label{eq:discretestateimpulse}
\begin{pmatrix}
x_{k} \\
s_{k} \\
\bz_{k} \\
q_{k} 
\end{pmatrix} = \begin{pmatrix}
x_{k} \\
s_{k} \\
\bz_{k} \\
q_{k}
\end{pmatrix}
+ \begin{pmatrix}
s_k - \xi \\
0 \\
0 \\
-1
\end{pmatrix}M_k^-
+ \begin{pmatrix}
- (s_k + \xi) \\
0 \\
0 \\
1
\end{pmatrix} M_k^+
\end{equation}
Our market orders assume immediate execution, and are assumed to be sufficiently small in volume so as to not affect order imbalance or the midprice. 

\subsection{Dynamic Programming}
The system formulation allows both continuous and impulse control to mimic what was done in the continuous time section, though in discrete time there is no \textit{a priori} distinction between the two \cite{Bens08}. The following theorem shows that in this case a quasi-variational inequality formulation does exist, and that it is equivalent to the standard dynamic programming formulation. The result is a simplified expression that mirrors the continuous time analysis.

\begin{thm}[\cite{Bens08}] \textbf{Dynamic Programming with Impulse Control in Discrete Time.} Consider a controlled Markov Chain with state space $X = \R^d$, transition probability $\pi(x, v, \d \eta)$, and positive, bounded, uniformly continuous cost function $l(x,v)$.

Introduce an impulse control $w$. Define the extended cost function by $l(x, v, w) = l(x + w, v) + c(w)$, the extended transition probability by $\pi (x, v, w, \d \eta) =  \pi (x+w, v, \d \eta)$ with the associated operator $\Phi^{v,w} f (x) = \int_{\R^d} f (\eta) \pi (x, v, w, \d \eta) = \Phi^{v} f (x+w)$.

Consider a decision rule $V,W$ with associated probability $\P^{V,W,x}$ on $\Omega, \cA$ for which $y_1 = x$ a.s. Consider the pay-off function
\begin{equation}
J_x (V, W ) = \E^{V,W,x} \left[ \sum\limits_{n=1}^\infty \alpha^{n-1} l(y_n,v_n,w_n) \right]
\end{equation}
and the corresponding Bellman equation
\begin{equation}\label{eq:DPDscrBellman}
u(x) = \inf\limits_{\substack{v \in U \\ w \geq 0}} [ l(x+w,v) + c(w) +  \alpha \Phi^{v} u (x+w) ]
\end{equation}
Assume:
\begin{enumerate}
\item $\Phi^V \phi_v(x)$ is continuous in $v, x$ if $\phi_v(x) = \phi(x, v)$ is uniformly continuous and bounded in $x, v$;
\item $c(w) = K \indicator_{w=0} + c_0 (w), \quad c_0(0)=0, \quad \quad c_0(w) \rightarrow \infty$ as $|w| \rightarrow \infty,$ \\ $c_0(w)$ is sub-linear positive continuous;
\item $U$ is compact.
\end{enumerate}
Then there exists a unique, positive, bounded solution of \eqref{eq:DPDscrBellman} belonging to the space of uniformly continuous and bounded functions. Further, this solution is identical to that of
\begin{equation}\label{eq:DPDscrAlt}
u(x) = \min \left\lbrace K + \inf\limits_{w \geq 0} [c_0(w) + u(x+w)] \; ; \; \inf\limits_{v \in U}  [l(x,v) + \alpha \Phi^v u(x)] \right\rbrace
\end{equation}
\end{thm}

\subsection{Maximizing Terminal Wealth (Discrete)}
Following the dynamic programming with impulse control programme, we introduce the value function $V_k^{\delta^\pm}$. Here, as in the continuous-time formulation, our objective is to maximize the terminal wealth performance criteria given by
\begin{equation}
V_k^{\delta^\pm} (x,s,\bz,q) = \E \left[ W_T^{\delta^\pm} \right] = \E_{k,x,s,\bz,q}\left[ X_T^{\delta^\pm} + Q_T^{\delta^\pm}(S_T - \sgn(Q_T^{\delta^\pm})\xi) - \alpha {(Q_T^{\delta^\pm})}^2 \right]
\end{equation}
where, as before, the notation $\E_{k,x,s,\bz,q}[ \; \cdot \; ]$ represents the conditional expectation
\[ \E [ \; \cdot \; | \; X_k = x, S_k = s, \bZ_k = \bz, Q_k = q] \]
In this case, our dynamic programming equations (DPEs) are given by
\begin{align}
V_T (x,s,\bz,q) & = x + q(s-\sgn(q)\xi) - \alpha q^2 \\
\label{eq:discreteDPEinitial}
\begin{split}
V_k (x,s,\bz,q) & = \max \biggl\lbrace \sup_{\delta^\pm} \bigl\lbrace \E_{\bw} \left[ V_{k+1} (f((x,s,\bz,q),\bu,\bw_k) \right] \bigr\rbrace \; ; \\
& \hphantom{{}={} \max \biggl\lbrace} V_k(x+s_k-\xi,s_k, \bz_k, q_k -1) \; ; \\
& \hphantom{{}={} \max \biggl\lbrace} V_k(x-s_k-\xi,s_k, \bz_k, q_k +1) \biggr\rbrace
\end{split}
\end{align}
where expectation is with respect to the random vector $\bw_k$. Note that in this formulation we do not have per stage costs, as the cost of execution is bundled into the state $x$. Nevertheless, it is rather immediate that the execution costs could be disentangled from the system state and seen to satisfy the theorem assumptions. Hypothetically we could add the fourth case where $M^+ = M^- = 1$, though a quick substitution shows that it is always strictly $2\xi$ less in value than the case of only limit orders, where $M^+ = M^- = 0$. This should be evident, as buying and selling with market orders in a single timestep yields a guaranteed loss as the agent is forced to cross the spread. 

To simplify the DPEs, we introduce a now familiar ansatz:
\begin{equation}
\label{eq:ansatzHdscr}
V_k (x,s,\bz,q) = x + q(s-\sgn(q)\xi) + h_k(\bz,q)
\end{equation}
with boundary condition $h_k(\bz,0) = 0$ and terminal condition $h_T(\bz,q) = -\alpha q^2$. Substituting this ansatz into the \eqref{eq:discreteDPEinitial}, we obtain
\begin{align}
\begin{split}
0 & = \max \biggl\lbrace \sup_{\delta^\pm} \bigl\lbrace \E_{\bw} \left[ V_{k+1} (f((x,s,\bz,q),\bu,\bw_k) \right] - V_k (x,s,\bz,q) \bigr\rbrace \; ; \\
& \hphantom{{}={} \max \biggl\lbrace} V_k(x+s_k-\xi,s_k, \bz_k, q_k -1) - V_k (x,s,\bz,q)\; ; \\
& \hphantom{{}={} \max \biggl\lbrace} V_k(x-s_k-\xi,s_k, \bz_k, q_k +1) - V_k (x,s,\bz,q) \biggr\rbrace
\end{split} \\
\label{eq:discreteDPE}
\begin{split}
0 & = \max \biggl\lbrace 
%%% Only Limit Orders
\sup_{\delta^\pm} \bigl\lbrace \E_{\bw} \bigl[
(s + \xi + \delta^-)L_k^- - (s - \xi - \delta^+)L_k^+ \\
& \hphantom{\sup_{\bu} \biggl\lbrace \E_{\bw} \biggl[ {}+{}} + (L_k^+ - L_k^-) \bigl( s + \eta_{0,T(\bz, \omega)}  -\sgn( q + L_k^+ - L_k^-)\xi   \bigr) \\
& \hphantom{\sup_{\bu} \biggl\lbrace \E_{\bw} \biggl[ {}+{}} + q\left( \eta_{0,T(\bz, \omega)}  -\left( \sgn( q + L_k^+ - L_k^-) - \sgn(q) \right) \xi \right) \\
& \hphantom{\sup_{\bu} \biggl\lbrace \E_{\bw} \biggl[ {}+{}} + h_{k+1}(T(\bz,\omega), q + L_k^+ - L_k^- ) -  h_k(\bz,q) \bigr] \bigr\rbrace \; ;\\
%%% Market Buy
& \hphantom{{}={} \max \biggl\lbrace } -2\xi \cdot \indicator_{q \geq 0} + h_k(\bz,q+1) \; ; \\
%%% Market Sell
& \hphantom{{}={} \max \biggl\lbrace } -2\xi \cdot \indicator_{q \leq 0} + h_k(\bz,q-1) \biggr\rbrace
\end{split}
\end{align}

We'll begin by concentrating on the first term in the quasi-variational inequality. Thus, we want to solve
\begin{equation}
\label{eq:discretesup1}
\begin{split}
& \sup_{\delta^\pm} \biggl\lbrace \E_{\bw} \biggl[
(s + \xi + \delta^-)L_k^- - (s - \xi - \delta^+)L_k^+ \\
& \hphantom{\sup_{\bu} \biggl\lbrace \E_{\bw} \biggl[ {}+{}} + (L_k^+ - L_k^-) \bigl( s + \eta_{0,T(\bz, \omega)}  -\sgn( q + L_k^+ - L_k^-)\xi   \bigr) \\
& \hphantom{\sup_{\bu} \biggl\lbrace \E_{\bw} \biggl[ {}+{}} + q\left( \eta_{0,T(\bz, \omega)}  -\left( \sgn( q + L_k^+ - L_k^-) - \sgn(q) \right) \xi \right) \\
& \hphantom{\sup_{\bu} \biggl\lbrace \E_{\bw} \biggl[ {}+{}} + h_{k+1}(T(\bz,\omega), q + L_k^+ - L_k^- ) -  h_k(\bz,q) \biggr] \biggr\rbrace
\end{split}
\end{equation}
As other agents' market orders as Poisson distributed, we have that 
\begin{equation}
[ K_k^+ = 0] = \frac{e^{-\mu^+ (\bz) \Delta t} (\mu^+ (\bz) \Delta t)^0}{0!} = e^{-\mu^+ (\bz) \Delta t}
\end{equation}
and so the probability of seeing some positive number of market orders is
\begin{equation}
\label{eq:discretepositiveKplus}
\P [ K_k^+ > 0] = 1 - e^{-\mu^+ (\bz) \Delta t}
\end{equation}
Now we make the simplified assumption that the \textit{aggregate} of the orders walks the limit order book to a depth of $p_k$, and if $p_k > \delta^-$, then our sell limit order is lifted. As in the continuous time section, we will assume that the probability of our order being lifted is $e^{-\kappa \delta^-}$. Thus we have the following preliminary results:
\begin{align}
\P [ L_k^- = 1 | K_k^+ > 0] & = e^{-\kappa \delta^-} \\
\P [ L_k^- = 0 | K_k^+ > 0] & = 1 - e^{-\kappa \delta^-} \\
\E [ L_k^- ] & = \P [ L_k^- = 1 | K_k^+ > 0] \cdot \P[K_k^+ > 0] \\
& = ( 1 - e^{-\mu^+ (\bz) \Delta t} ) e^{-\kappa \delta^-}
\end{align}
For ease of notation, we'll write the probability of the $L_k^- = 1$ event as $p(\delta^-)$. This gives us the additional results:
\begin{align}
\P [ L_k^- = 1] & = p(\delta^-) = \E [ L_k^-] \\
\P [ L_k^- = 0] & = 1 - p(\delta^-) \\
\partial_{\delta^-} \P [ L_k^- = 1]  & = -\kappa p(\delta^-) \\
\partial_{\delta^-} \P [ L_k^- = 0] & = \kappa p(\delta^-)
\end{align}
Let's pre-compute some of the terms that we'll encounter in the supremum, namely the expectations of the random variables. To each we will assign an uppercase Greek letter as shorthand, as will be evident from the analysis.
\begin{align}
\begin{split}
\E [\sgn(q + L_k^+ - L_k^-)] & = \P[L_k^- = 1] \cdot \P[L_k^+ = 1] \cdot \sgn(q) \\
& \quad + \P[L_k^- = 1] \cdot \P[L_k^+ = 0] \cdot \sgn(q - 1) \\
& \quad +  \P[L_k^- = 0] \cdot \P[L_k^+ = 1] \cdot \sgn(q+1) \\
& \quad + \P[L_k^- = 0] \cdot \P[L_k^+ = 0] \cdot \sgn(q) 
\end{split} \\
\begin{split}
& = p(\delta^-)p(\delta^+) \sgn(q)  \\
& \quad + p(\delta^-) (1-p(\delta^+)) \sgn(q - 1)  \\
& \quad + (1 - p(\delta^-)) p(\delta^+)  \sgn(q+1)  \\
& \quad + (1 - p(\delta^-)) (1-p(\delta^+))  \sgn(q)
\end{split} \\
\begin{split}
& = \sgn(q) \bigl[ 1 - p(\delta^+) - p(\delta^-) + 2 p(\delta^+) p(\delta^-) \bigr] \\
& \quad + \sgn(q-1) \bigl[ p(\delta^-)  - p(\delta^+) p(\delta^-) \bigr] \\
& \quad + \sgn(q+1) \bigl[ p(\delta^+)  - p(\delta^+) p(\delta^-) \bigr]
\end{split} \\
& = \begin{cases} 
1 & q \geq 2 \\
1 - p(\delta^-)(1 - p(\delta^+)) & q = 1 \\
p(\delta^+) - p(\delta^-) & q = 0 \\
-\bigl[ 1 - p(\delta^+)(1 - p(\delta^-)) \bigr] & q = -1 \\
-1 & q \leq -2
\end{cases} \\
& = \Phi(q, \delta^+, \delta^-)
\end{align}
Similarly:
\begin{align}
\begin{split}
\E [ L_k^+ \sgn(q + L_k^+ - L_k^-)] & = \P[L_k^- = 1] \cdot \P[L_k^+ = 1] \cdot \sgn(q) \\
& \quad + \P[L_k^- = 1] \cdot \P[L_k^+ = 0] \cdot 0 \sgn(q - 1) \\
& \quad +  \P[L_k^- = 0] \cdot \P[L_k^+ = 1] \cdot \sgn(q+1) \\
& \quad + \P[L_k^- = 0] \cdot \P[L_k^+ = 0] \cdot 0 \sgn(q)
\end{split} \\
& = p(\delta^+) \bigl[ p(\delta^-) \sgn(q) + (1-p(\delta^-) \sgn(q+1) \bigr] \\
& = p(\delta^+) \begin{cases} 
1 & q \geq 2 \\
1 & q = 1 \\
(1 - p(\delta^-)) & q = 0 \\
-p(\delta^-) & q = -1 \\
-1 & q \leq -2
\end{cases} \\
& = p(\delta^+) \Psi(q, \delta^-)
\end{align}
and
\begin{align}
\E [ L_k^- \sgn(q + L_k^+ - L_k^-)] & = p(\delta^-) \bigl[ p(\delta^+) \sgn(q) + (1-p(\delta^+)) \sgn(q-1) \bigr] \\
& = p(\delta^-) \begin{cases} 
1 & q \geq 2 \\
p(\delta^+) & q = 1 \\
-(1 - p(\delta^+)) & q = 0 \\
-1 & q = -1 \\
-1 & q \leq -2
\end{cases} \\
& = p(\delta^-) \Upsilon(q, \delta^+)
\end{align}
We'll also require the partial derivatives of these expectations, which we can easily compute. Below we'll use the simplified notation $\Phi_+$ to denote the function closely associated with the partial derivative of $ \Phi$ with respect to $\delta^+$.
\begin{align}
\partial_{\delta^-} \E [\sgn(q + L_k^+ - L_k^-)] = \partial_{\delta^-} \Phi(q, \delta^+, \delta^-) & = \kappa p(\delta^-) \begin{cases} 
0 & q \geq 2 \\
(1-p(\delta^+)) & q = 1 \\
1 & q = 0 \\
p(\delta^+)  & q = -1 \\
0 & q \leq -2
\end{cases} \\
& = \kappa p(\delta^-) \Phi_-(q,\delta^+) \\
\partial_{\delta^+} \E [\sgn(q + L_k^+ - L_k^-)] =\partial_{\delta^+} \Phi(q, \delta^+, \delta^-) & =  \kappa p(\delta^+) \begin{cases} 
0 & q \geq 2 \\
- p(\delta^-) & q = 1 \\
- 1 & q = 0 \\
- (1 - p(\delta^-)) & q = -1 \\
0 & q \leq -2
\end{cases} \\
& = \kappa p(\delta^+)\Phi_+(q,\delta^-) \\
\partial_{\delta^-} \E [L_k^+ \sgn(q + L_k^+ - L_k^-)] = \partial_{\delta^-} p(\delta^+) \Psi(q, \delta^-) & = \kappa p(\delta^+) p(\delta^-)\begin{cases} 
0 & q \geq 2 \\
0 & q = 1 \\
1 & q = 0 \\
1 & q = -1 \\
0 & q \leq -2
\end{cases} \\
& = \kappa p(\delta^+) p(\delta^-) \Psi_-(q) \\
\partial_{\delta^+} \E [L_k^+ \sgn(q + L_k^+ - L_k^-)] = \partial_{\delta^+} p(\delta^+) \Psi(q, \delta^-) & = -\kappa p(\delta^+) \Psi(q, \delta^-)
 \\
\partial_{\delta^-} \E [L_k^- \sgn(q + L_k^+ - L_k^-)] = \partial_{\delta^-} p(\delta^-) \Upsilon(q, \delta^+) & = -\kappa p(\delta^-) \Upsilon(q, \delta^+)
 \\
 \partial_{\delta^+} \E [L_k^- \sgn(q + L_k^+ - L_k^-)] = \partial_{\delta^+} p(\delta^-) \Upsilon(q, \delta^+)& = \kappa p(\delta^+) p(\delta^-) \begin{cases} 
0 & q \geq 2 \\
-1 & q = 1 \\
-1 & q = 0 \\
0 & q = -1 \\
0 & q \leq -2
\end{cases} \\
& = \kappa p(\delta^+) p(\delta^-)\Upsilon_+(q)
\end{align}
Recalling that we have  $\bP$ the transition matrix for the Markov Chain $\bZ$, with $\bP_{\bz, \bj} = \P[\bZ_{k+1} = \bj | \bZ_k = \bz]$, then we can also write:
\begin{equation}
\begin{split}
\E[h_{k+1}(T(\bz,\omega), q + L_k^+ - L_k^- )] & = \sum_\bj \bP_{\bz,\bj} \biggl[ h_{k+1}(\bj, q) \bigl[ 1 - p(\delta^+) - p(\delta^-) + 2 p(\delta^+) p(\delta^-) \bigr]  \\
& \hphantom{\sum_\bj \bP_{\bz,\bj} \biggl[ {}+{}} + h_{k+1}(\bj, q-1) \bigl[ p(\delta^-)  - p(\delta^+) p(\delta^-) \bigr]   \\
& \hphantom{\sum_\bj \bP_{\bz,\bj} \biggl[ {}+{}} + h_{k+1}(\bj, q+1) \bigl[ p(\delta^+)  - p(\delta^+) p(\delta^-) \bigr] \biggr]
\end{split}
\end{equation}
and its partial derivatives as
\begin{align}
\begin{split}
\partial_{\delta^-} \E[h_{k+1}(T(\bz,\omega), q + L_k^+ - L_k^- )] & = 
\sum_\bj \bP_{\bz,\bj} \biggl[ h_{k+1}(\bj, q) \bigl[ \kappa p(\delta^-) - 2 \kappa p(\delta^+) p(\delta^-) \bigr]  \\
& \hphantom{\sum_\bj \bP_{\bz,\bj} \biggl[ {}+{}} + h_{k+1}(\bj, q-1) \bigl[ -\kappa p(\delta^-) + \kappa p(\delta^+) p(\delta^-) \bigr]   \\
& \hphantom{\sum_\bj \bP_{\bz,\bj} \biggl[ {}+{}} + h_{k+1}(\bj, q+1) \bigl[ \kappa p(\delta^+) p(\delta^-) \bigr] \biggr]
\end{split} \\
\begin{split}
& = \kappa p(\delta^-) \sum_\bj \bP_{\bz,\bj} \biggl[ h_{k+1}(\bj, q) \bigl[ 1 - 2 p(\delta^+) \bigr]  \\
& \hphantom{d(\delta^-) \sum_\bj \bP_{\bz,\bj} \biggl[ {}+{}} + h_{k+1}(\bj, q-1) \bigl[-1 + p(\delta^+) \bigr]   \\
& \hphantom{d(\delta^-) \sum_\bj \bP_{\bz,\bj} \biggl[ {}+{}} + h_{k+1}(\bj, q+1) \bigl[ p(\delta^+) \bigr] \biggr]
\end{split} \\
\begin{split}
\partial_{\delta^+} \E[h_{k+1}(T(\bz,\omega), q + L_k^+ - L_k^- )] & = 
\kappa p(\delta^+) \sum_\bj \bP_{\bz,\bj} \biggl[ h_{k+1}(\bj, q) \bigl[ 1 - 2 p(\delta^-) \bigr]  \\
& \hphantom{d(\delta^-) \sum_\bj \bP_{\bz,\bj} \biggl[ {}+{}} + h_{k+1}(\bj, q-1) \bigl[ p(\delta^-) \bigr]   \\
& \hphantom{d(\delta^-) \sum_\bj \bP_{\bz,\bj} \biggl[ {}+{}} + h_{k+1}(\bj, q+1) \bigl[ -1 + p(\delta^-) \bigr] \biggr]
\end{split}
\end{align}

Now we tackle solving the supremum in equation $\ref{eq:discretesup1}$ and thus finding the optimal posting depths, again denoted by a subscript asterisk. First we consider the first-order condition on $\delta^-$, namely that the partial derivative with respect to it must be equal to zero.
\begin{align}
\begin{split}
0 & = \partial_{\delta^-} \biggl\lbrace 
(s + \xi + {\delta^-}^*)\E [L_k^-] - (s - \xi - \delta^+)\E[L_k^+] \\
& \hphantom{\partial_{\delta^-} \biggl\lbrace {}+{}} + \E[L_k^+] \left( s + \E[\eta_{0,T(\bz, \omega)}] \right)  - \xi \E \left[L_k^+ \sgn( q + L_k^+ - L_k^-) \right] \\
& \hphantom{\partial_{\delta^-} \biggl\lbrace {}+{}} - \E[L_k^-] \left( s + \E[\eta_{0,T(\bz, \omega)}] \right) + \xi \E \left[ L_k^- \sgn( q + L_k^+ - L_k^-) \right] \\
& \hphantom{\partial_{\delta^-} \biggl\lbrace {}+{}} + q \E[ \eta_{0,T(\bz, \omega)}]  - q \xi \E[ \sgn( q + L_k^+ - L_k^-)] + q \xi \sgn(q)  \\
& \hphantom{\partial_{\delta^-} \biggl\lbrace {}+{}} + \E \left[ h_{k+1}(T(\bz,\omega), q + L_k^+ - L_k^- ) \right] -  h_k(\bz,q) \biggr\rbrace
\end{split} \\
\begin{split}
& = \partial_{\delta^-} \biggl\lbrace 
(s + \xi + {\delta^-}^*)\E [L_k^-] - \xi \E \left[L_k^+ \sgn( q + L_k^+ - L_k^-) \right] \\
& \hphantom{\partial_{\delta^-} \biggl\lbrace {}+{}} - \E[L_k^-] \left( s + \E[\eta_{0,T(\bz, \omega)}] \right) + \xi \E \left[ L_k^- \sgn( q + L_k^+ - L_k^-) \right] \\
& \hphantom{\partial_{\delta^-} \biggl\lbrace {}+{}} - q \xi \E[ \sgn( q + L_k^+ - L_k^-)]  + \E \left[ h_{k+1}(T(\bz,\omega), q + L_k^+ - L_k^- ) \right]  \biggr\rbrace
\end{split} \\
\begin{split}
& = p({\delta^-}^*) - \kappa p({\delta^-}^*) (s + \xi + {\delta^-}^*) - \xi \kappa p(\delta^+)p({\delta^-}^*)\Psi_-(q) \\
& \hphantom{{}={}} + \kappa p({\delta^-}^*) \left( s + \E[\eta_{0,T(\bz, \omega)}] \right) - \xi \kappa p({\delta^-}^*) \Upsilon(q,\delta^+) - q \xi \kappa p({\delta^-}^*) \Phi_-(q,\delta^+) \\
& \hphantom{{}={}} + \kappa p({\delta^-}^*) \sum_\bj \bP_{\bz,\bj} \biggl[ h_{k+1}(\bj, q) \bigl[ 1 - 2 p(\delta^+) \bigr] + h_{k+1}(\bj, q-1) \bigl[-1 + p(\delta^+) \bigr] \\
& \hphantom{{}={} + \kappa p({\delta^-}^*) \sum_\bj \bP_{\bz,\bj} \biggl[} + h_{k+1}(\bj, q+1) \bigl[ p(\delta^+) \bigr] \biggr]
\end{split}
\end{align}
Dividing through by $\kappa p({\delta^-}^*)$, which is nonzero, and re-arranging, we find that the optimal sell posting depth is given by
\begin{align}
\begin{split}
{\delta^-}^* & = \frac{1}{\kappa} + \E[\eta_{0,T(\bz, \omega)}] - \xi \left( 1 + p(\delta^+)\Psi_-(q) + \Upsilon(q,\delta^+) + q \Phi_-(q,\delta^+) \right) \\
& \hphantom{{}={}} +  \sum_\bj \bP_{\bz,\bj} \biggl[ h_{k+1}(\bj, q) \bigl[ 1 - 2 p(\delta^+) \bigr] + h_{k+1}(\bj, q-1) \bigl[-1 + p(\delta^+) \bigr] + h_{k+1}(\bj, q+1) \bigl[ p(\delta^+) \bigr] \biggr]
\end{split} \\
\begin{split}
& = \frac{1}{\kappa} + \E[\eta_{0,T(\bz, \omega)}] - 2 \xi \left( \indicator_{q \geq 1} + p(\delta^+)\indicator_{q = 0} \right) \\
& \hphantom{{}={}} +  \sum_\bj \bP_{\bz,\bj} \biggl[ h_{k+1}(\bj, q) \bigl[ 1 - 2 p(\delta^+) \bigr] + h_{k+1}(\bj, q-1) \bigl[-1 + p(\delta^+) \bigr] + h_{k+1}(\bj, q+1) \bigl[ p(\delta^+) \bigr] \biggr]
\end{split}
\end{align}
Recalling that we want $\delta^\pm \geq 0$, we find:
\begin{equation}\label{eq:discretedeltaminusreferential}
\begin{split}
{\delta^-}^* & = \max \biggl\lbrace 0 \; ; \; \frac{1}{\kappa} + \E[\eta_{0,T(\bz, \omega)}] - 2 \xi \indicator_{q \geq 1} + \sum_\bj \bP_{\bz,\bj} \bigl[ h_{k+1}(\bj, q) - h_{k+1}(\bj, q-1) \bigr] \\
& \hphantom{{}={}} -p(\delta^+) \left( 2 \xi \indicator_{q = 0} - \sum_\bj \bP_{\bz,\bj} \bigl[ h_{k+1}(\bj, q-1) + h_{k+1}(\bj, q+1) -2 h_{k+1}(\bj, q)  \bigr] \right) \biggr\rbrace
\end{split}
\end{equation}
And similarly, the optimal buy posting depth is given by:
\begin{equation}\label{eq:discretedeltaplusreferential}
\begin{split}
{\delta^+}^* & = \max \biggl\lbrace 0 \; ; \; \frac{1}{\kappa} - \E[\eta_{0,T(\bz, \omega)}] - 2 \xi \indicator_{q \leq -1} + \sum_\bj \bP_{\bz,\bj} \bigl[ h_{k+1}(\bj, q) - h_{k+1}(\bj, q+1) \bigr] \\
& \hphantom{{}={}} -p(\delta^-) \left( 2 \xi \indicator_{q = 0} - \sum_\bj \bP_{\bz,\bj} \bigl[ h_{k+1}(\bj, q-1) + h_{k+1}(\bj, q+1) -2 h_{k+1}(\bj, q)  \bigr] \right) \biggr\rbrace
\end{split}
\end{equation}
For ease of notation we'll write $\aleph(q) = \sum_\bj \bP_{\bz,\bj} \left[ h_{k+1}(\bj, q-1) + h_{k+1}(\bj, q+1) -2 h_{k+1}(\bj, q)  \right]$. Now, assuming we behave optimally on both the buy and sell sides simultaneously, we can substitute equation \ref{eq:discretedeltaplusreferential} into equation \ref{eq:discretedeltaminusreferential}, while evaluating both at ${\delta^+}^*$ and ${\delta^-}^*$ to obtain the optimal posting depth in feedback form:
\begin{equation}\label{eq:discretedeltaminusfeedback}
\begin{split}
{\delta^-}^* & = \frac{1}{\kappa} + \E[\eta_{0,T(\bz, \omega)}] - 2 \xi \indicator_{q \geq 1} + \sum_\bj \bP_{\bz,\bj} \biggl[ h_{k+1}(\bj, q) - h_{k+1}(\bj, q-1) \biggr] \\
& \hphantom{{}={}} - (1-e^{\mu^-(\bz) \Delta t})e^{-\kappa \max \bigl\lbrace 0 \; ; \; \frac{1}{\kappa} - \E[\eta_{0,T(\bz, \omega)}] - 2 \xi \indicator_{q \leq -1} + \sum_\bj \bP_{\bz,\bj} \bigl[ h_{k+1}(\bj, q) - h_{k+1}(\bj, q+1) \bigr]} \\
& \hphantom{{}={} {}-{}} {}^{-(1-e^{\mu^+ (\bz) \Delta t})e^{-\kappa {\delta^-}^*} \left( 2 \xi \indicator_{q = 0} - \aleph(q) \right) \bigr\rbrace } \left( 2 \xi \indicator_{q = 0} - \aleph(q) \right)
\end{split}
\end{equation}
This equation will need to be solved numerically due to the difficulty in isolating ${\delta^{-}}^*$ on one side of the equality. Once a solution has been obtained, the value can be substituted back into \eqref{eq:discretedeltaplusreferential} to solve for ${\delta^{+}}^*$.

\subsection{Simplifying the DPE}
We now turn to simplifying the DPE in \eqref{eq:discreteDPE} by substituting in the optimal posting depths as written in recursive form: \eqref{eq:discretedeltaplusreferential} and \eqref{eq:discretedeltaminusreferential}. In doing so we see a incredible amount of cancellation and simplification, and we obtain the rather elegant, and surprisingly simple form of the DPE:
\begin{equation}
\label{eq:discreteDPEfinal}
\begin{split}
h_k(\bz,q) & = \max \biggl\lbrace 
%%% Only Limit Orders
q\E[\eta_{0,T(\bz, \omega)}] + \frac{1}{\kappa}(p({\delta^+}^*)+p({\delta^-}^*))  + \sum_{\bj} \bP_{\bz,\bj} h_{k+1}(\bj,q) \\ 
& \hphantom{{}={} \max \biggl\lbrace {}+{}} + p({\delta^+}^*)p({\delta^-}^*)\sum_\bj \bP_{\bz,\bj} \left[ h_{k+1}(\bj, q-1) + h_{k+1}(\bj, q+1) -2 h_{k+1}(\bj, q)  \right] \; ; \\
%%% Market Buy
& \hphantom{{}={} \max \biggl\lbrace } -2\xi \cdot \indicator_{q \geq 0} + h_k(\bz,q+1) \; ; \\
%%% Market Sell
& \hphantom{{}={} \max \biggl\lbrace } -2\xi \cdot \indicator_{q \leq 0} + h_k(\bz,q-1) \biggr\rbrace
\end{split}
\end{equation}
% Note to self: I removed -2\xi p({\delta^+}^*)p({\delta^-}^*) \indicator_{q=0} from the final DPE, because we know that at q=0 h=0. 
As was the case in continuous time, \eqref{eq:discreteDPEfinal} yields that whilst in the continuation region, we have
\begin{align}
h_k(\bz,q) & \leq h_k(\bz, q+1) - 2 \xi \cdot \indicator_{q \geq 0} \\
h_k(\bz,q) & \leq h_k(\bz, q-1) - 2 \xi \cdot \indicator_{q \leq 0}
\end{align}
And these inequalities again give us
\begin{align}
-2\xi \cdot \indicator_{q \geq 0} & \leq h_k(\bz,q) - h_k(\bz,q+1) \leq 2\xi \cdot \indicator_{q \leq -1} \label{eq:dscrMOineq1}\\
-2\xi \cdot \indicator_{q \leq 0} & \leq h_k(\bz,q) - h_k(\bz,q-1) \leq 2\xi \cdot \indicator_{q \geq 1} \label{eq:dscrMOineq2}\\[4ex]
h_k(\bz,q) & \overset{\text{\makebox[0pt]{sell if =}}}{\overset{\downarrow}{\leq}} h_k(\bz,q+1) \overset{\text{\makebox[0pt]{buy if =}}}{\overset{\downarrow}{\leq}} h_k(\bz,q) + 2\xi, \qquad q \geq 0 \label{eq:dscrMOineq3}\\
h_k(\bz,q) & \underset{\text{\makebox[0pt]{buy if =}}}{\underset{\uparrow}{\leq}} h_k(\bz,q-1) \underset{\text{\makebox[0pt]{sell if =}}}{\underset{\uparrow}{\leq}} h_k(\bz,q) + 2\xi, \qquad q \leq 0 \label{eq:dscrMOineq4}
\end{align}
Recalling the boundary condition $h_k(\bz,0) = 0$, \eqref{eq:dscrMOineq3} and \eqref{eq:dscrMOineq4} tell us that the function $h$ is non-negative everywhere.

At terminal time $T$, we liquidate our position at a cost of $(s - xi \sgn(q) - \alpha q)$ per share, whereas at $T-1$, we can liquidate at the regular cost of $(s - \xi \sgn(q)$. It is thus never optimal to wait until maturity to liquidate the position, and instead we force liquidation one step earlier by setting $h(T-1,\bz,q) = 0 \; \forall q$. This allows us to effectively ignore the terminal condition, and avoids a contradiction with the finding that $h \geq 0$.

We now have an explicit means of numerically solving for the optimal posting depths. Since we know the function $h$ at the terminal timesteps $T$ and $T-1$, we can take one step back to $T-2$ and solve for both the optimal posting depths. With these values we are then able to calculate the value function $h_{T-2}$ using \eqref{eq:discreteDPEfinal}, and in doing so determine whether to execute market orders in addition to posting limit orders. This process then repeats for each step backward.