\chapter{Exploratory Data Analysis}

\section{Modelling Imbalance: Continuous Time Markov Chain}
The key aim of this research project is to utilize the LOB volume imbalance $I(t)$, and as such we require a suitable model for that stochastic process. Rather than modelling imbalance directly as a real-valued process, an alternative approach is to discretize imbalance into subintervals, or bins, and model a stochastic process that tracks into which bin $I(t)$ falls. A particularly simple yet powerful choice is the Continuous Time Markov Chain (CTMC).

Let $Z(t)$ be a CTMC taking values in $\left\lbrace 1,\dots , K \right\rbrace$, and having transition probabilities $P_{ij}(t) = P \lbrace Z(t) = j | Z(0) = i \rbrace$ and transition matrix $\mat{P}(t) = \lbrace P_{ij}(t) \rbrace$. $Z(t)$ additionally has a so-called \textit{infinitesimal generator matrix} $\mat{G}$, where the matrices $\mat{P}(t)$ and $\mat{G}$ satisfy
\[\dot{\mat{P}}(t) = \mat{G} \cdot \mat{P}(t) \]
\[\mat{P}(t) = e^{\mat{G}t} \]
Conditional on $Z(t) = k$, we will assume the arrival of buy and sell market orders follow independent Poisson processes with intensities $\lambda_k^\pm$, where $\lambda_k^+$ ($\lambda_k^-$) is the rate of arrivals of market buys (resp. sells). Such processes are hence called \textit{Markov-modulated Poisson processes}.

\section{Maximum Likelihood Estimate of a Markov-modulated Poisson Process}

\subsection{Maximum Likelihood Estimation of \texorpdfstring{$G$}{G}}

Let $G$ be the generator matrix for $Z_t$, so $G = \{ q_{ij} \} \in \mathbb{R}^{K \times K}$ where $q_{ij}$ are the transition rates from regime $i$ to regime $j$ for $i\neq j$, and $q_{ii} = - \sum\limits_{j \neq i} q_{ij}$ so that the rows of $G$ sum to 0. 

When $Z_t$ enters regime $i$, the amount of time it spends in regime $i$ is exponentially distributed with rate $v_i = \sum\limits_{j \neq i} q_{ij}$, and when it leaves regime $i$ it will to go regime $j$ with probability $p_{ij} = \dfrac{q_{ij}}{v_i}$. 

From our observations we want to estimate the components of $G$. The holding time in a given regime $i$ is exponentially distributed with pdf $f(t;v_i) = v_i e^{-v_i t}$. For the fictional events in the timeline given in Figure \ref{introtimeline}, the likelihood function (allowing for repetition of terms) would therefore be:

\begin{align}
\mathcal{L}(G) &= (v_{i} e^{-v_{i}(\tau_2 - \tau_1)} p_{ij}) (v_{j} e^{-v_{j}(\tau_3 - \tau_2)} p_{ji}) (v_{i} e^{-v_{i}(\tau_4 - \tau_3)} p_{ik}) \dots \\
&= \prod\limits_{i=1}^{K} \prod\limits_{i \neq j} (v_{i}p_{ij})^{N_{ij}(T)} e^{-v_{i}H_i(T)} \\
&= \prod\limits_{i=1}^{K} \prod\limits_{i \neq j} (q_{ij})^{N_{ij}(T)} e^{-v_{i}H_i(T)} \\
\intertext{where:}
N_{ij}(T) & \equiv \mbox{number of transitions from regime $i$ to $j$ up to time $T$} \nonumber \\
H_{i}(T) & \equiv \mbox{holding time in regime $i$ up to time $T$} \nonumber \\
\intertext{So that the log-likelihood becomes:} 
\ln \mathcal{L}(G) & = \sum\limits_{i=1}^{K} \sum\limits_{i \neq j} \left[ N_{ij}(T) \ln(q_{ij}) - v_{i} H_i(T) \right] \\
&= \sum\limits_{i=1}^{K} \sum\limits_{i \neq j} \left[ N_{ij}(T) \ln(q_{ij}) - \left( \sum\limits_{i \neq k} q_{ik} H_i(T) \right) \right]
\end{align}

To get a maximum likelihood estimate $\hat{q}_{ij}$ for transition rates and therefore the matrix $G$, we take the partial derivative of $\ln \mathcal{L}(G)$ and set it equal to zero:

\begin{equation}
\dfrac{\partial \ln \mathcal{L}(G)}{\partial q_{ij}} = \dfrac{N_{ij}(T)}{q_{ij}} - H_i(T) = 0
\end{equation}
\begin{equation}
\Rightarrow \boxed{ \hat{q}_{ij} = \dfrac{N_{ij}(T)}{H_i(T)} }
\end{equation}

\subsection{Maximum Likelihood Estimation of \texorpdfstring{$\lambda^{\pm}_k$}{lpmk}}

Now we want to derive an estimate for the intensity of the Poisson process of market order arrivals conditional on being in some bin $k$. We'll look first at just the market buys for some regime $k$. In the above timeline, the market order buy arrival times are indexed by $b_i$. Since we're assuming that the arrival process is Poisson with the same intensity throughout trials, we can consider the inter-arrival time of events conditional on being in regime $k$. Then the MLE derivation follows just as for the CTMC:

\begin{align}
\mathcal{L}(\lambda^{+}_k ; b_1, \dots, b_N) &= \prod\limits_{i=2}^{N} \lambda^{+}_k e^{-\lambda^{+}_k (b_{i} - b_{i-1})} \\
&= (\lambda^{+}_k)^{N^{+}_k(T)} e^{-\lambda^{+}_k H_k(T)} \\
\intertext{where:}
N^{+}_{k}(T) & \equiv \mbox{number of market order arrivals in regime $k$ up to time $T$} \nonumber \\
H_{k}(T) & \equiv \mbox{holding time in regime $k$ up to time $T$} \nonumber \\
\intertext{So that the log-likelihood becomes:} 
\ln \mathcal{L}(\lambda^{+}_k) & = N^{+}_k(T) \ln(\lambda^{+}_k) -\lambda^{+}_k H_k(T)
\intertext{And the ML estimate for $\hat{\lambda}^{+}_k$ is:} 
\dfrac{\partial \ln\mathcal{L} }{\partial \lambda^{+}_k} & = 
\dfrac{N^{+}_k(T)}{\lambda^{+}_k} - H_k(T) = 0
\end{align}
\begin{equation}
\Rightarrow \boxed{ \hat{\lambda}^{+}_k = \dfrac{N^{+}_k(T)}{H_k(T)} }
\end{equation}

\section{Cross-validation of CTMC}
Given a set of observations of buy/sell market orders and regime switches, in the previous section we derived a maximum likelihood estimation (MLE) for both the entries of the infinitesimal generator matrix $\mat{G}$, and the market order arrival rates $\lambda_k^\pm$. 

We estimated parameters for a CTMC on a day's worth of LOB data.
Using these parameters, we generated sample paths of the imbalance bins as well as arrival of market orders,
and re-estimated parameters along the sample paths. By doing this for 10,000 paths we obtained histograms for
the parameters (the individual entries of $\mat{G}$ as well as the intensities $\lambda_k^\pm$). 

Using data for \texttt{ORCL} from 2013-05-15, averaging imbalances over a 100ms window, and taking the number
of bins $K=3$, we obtained the following mean values for the parameters:

\[ \mat{G} = \begin{pmatrix} -0.112 & 0.098 & 0.0122 \\
							0.099 & -0.21 & 0.111 \\
							0.0115 & 0.112 & -0.1235 \end{pmatrix} \]
							
\[ \mat{\lambda} = \bordermatrix{  & k=1    & k=2   & k=3   \cr
								+ & 0.121  & 0.081 & 0.048 \cr
								- & 0.0263 & 0.062 & 0.153 } \]

To cross-validate the CTMC calibration, the following steps were taken:
\begin{enumerate}
\item An imbalance averaging time (in ms) and number of imbalance bins were fixed. The infinitesimal generator matrix $\mat{G}$ was calculated on the resulting timeseries. 
\item An embedded discrete Markov chain transition matrix $\mat{A}$ was obtained from $\mat{G}$. This effectively says: conditional on a transition from bin $i$, what are the transition probabilities to bin $j$?
\item The stationary distribution, and number ($n$) of steps required to converge to the stationary distribution, was calculated. That is: for $\epsilon > 0$, calculate $n$ such that $||\mat{A}^{n+1} - \mat{A}^n|| < \epsilon$.
\item Find the average number of steps in the timeseries that are required to observe $n$ transitions. This is the size of the timewindow against which to cross-validate. 
\item Remove the cross-validation timewindow (call this the ``removed series'') from the full timeseries (call this the ``remaining series''). Calculate two infinitesimal generator matrices $\mat{G}_{removed}$ and $\mat{G}_{remaining}$.
\item Calculate two error terms for the resulting matrices:
$$err = \sqrt{\dfrac{1}{\#trials} \times \sum\limits_{trials} \left( \dfrac{1}{\#bins^2} \sum\limits_{ij} (\mat{G}_{remaining}(ij) - \mat{G}_{removed}(ij))^2 \right)x} $$
$$\mat{Err} = \sqrt{\dfrac{1}{\#trials} \times \sum\limits_{trials} (\mat{1} - \mat{G}_{removed} \div \mat{G}_{remaining})^2 }$$
where, for $\mat{Err}$, division and squaring are entry-wise and not matrix-wise.
\end{enumerate}

This is following up on the cross-validation results from last time. In those results, in order to obtain the invariant distribution for the Markov chain, we calculated a transition probability matrix $\mat{A}$ for the embedded discrete-time Markov chain and took matrix powers $\mat{A}^n$ until it converged, and then observed the average number of timesteps that it took to see $n$ transitions in the data.

In these results, we instead use the relationship $\dot{\mat{P}} (t) = \mat{P}(t)\mat{G} \; \Rightarrow \; \mat{P}(t) = e^{t\mat{G}}$. Thus we calculate the invariant distribution using the averaging time $\Delta t$ and the number of such timesteps $n$ and observe when $e^{\Delta t\mat{G}n}$ converges. This value $n$ immediately tells us the timewindow size to remove for cross-validation.

\begin{table}[H]
\small
\centering
\caption{New results, convergence threshold 1e-05}
\vspace*{2.5mm}
\begin{tabular}{c|c|c|c|c}
\hline
\bf \# bins & & & & \\ averaging time & stationary $n$ & Timewindow size & $err$ & $\mat{Err}$ \\
\hline\hline
3 bins, 100ms & 478 & 47.8s (0.2\% of series) & 0.356402 & 644\% - 11371\% \\
\hline
3 bins, 500ms & 144 & 72s (0.3\% of series) & 0.087631 & 236\% - 985\% \\
\hline
3 bins, 1000ms & 89 & 89s (0.4\% of series) &  0.050605 & 150\% - 480\% \\
\hline
3 bins, 2000ms & 57 & 114s (0.5\% of series) & 0.032076 & 122\% - 725\% \\
\hline
3 bins, 3000ms & 45 & 135s (0.6\% of series) & 0.023662 & 98\% - 552\% \\
\hline
3 bins, 5000ms & 35 & 175s (0.75\% of series) & 0.014182 & 70\% - 514\% \\
\hline
3 bins, 10000ms & 29 & 290s (1.2\% of series) & 0.007361 & 52\% - 496\% \\
\hline
3 bins, 20000ms & 22 & 440s (1.9\% of series) & 0.004447 & 43\% - 1698\% \\
\hline
\hline
5 bins, 100ms & 546 & 54.6s (0.2\% of series) & 0.162690 & 452\% - 6785\% \\
\hline
5 bins, 500ms & 162 & 81s (0.3\% of series) &  0.046204 & 187\% - 2590\% \\
\hline
5 bins, 1000ms & 100 & 100s (0.4\% of series) & 0.029900 & 136\% - 2962\% \\
\hline
5 bins, 2000ms & 65 & 130s (0.6\% of series)  & 0.017340 & 86\% - 2141\% \\
\hline
5 bins, 3000ms & 52 & 156s (0.7\% of series) &  0.012505 & 87\% - Inf\% \\
\hline
5 bins, 5000ms & 42 & 210s (0.9\% of series) & 0.008035 & 66\% - 978\% \\
\hline
5 bins, 10000ms & 31 & 310s (1.3\% of series) & 0.004563 & 45\% - Inf\% \\
\hline
5 bins, 20000ms & 25 & 500s (2.1\% of series) & 0.002485 & 42\% - Inf\% \\
\hline
\end{tabular}
\end{table}

The large errors seen in the error matrix $\mat{Err}$ are attributable to the corner elements: in the case of 3 bins, this would be $G_{13}$ and $G_{31}$. Or, for example, the error matrices for 5 bins at 100ms and at 20000ms looked like:

$$\mat{Err}_{100ms} = \begin{bmatrix}
    6.86 &   8.48 &   5.92 &   9.68 &  11.02\\
    7.57 &   6.82 &   8.80 &  67.58 &   8.31\\
    6.33 &   5.08 &   4.52 &   8.55 &  16.79\\
   14.64 &  54.50 &   8.12 &   6.41 &   7.77\\
    6.82 &  36.76 &   5.47 &   5.86 &   5.04
\end{bmatrix}$$

$$\mat{Err}_{20000ms} = \begin{bmatrix}
    0.79 &   0.99 &   3.63 &  20.23 &    Inf\\
    1.10 &   0.44 &   0.82 &   1.36 &    NaN\\
    2.07 &   0.64 &   0.42 &   0.88 &   3.83\\
    3.64 &   1.66 &   0.85 &   0.57 &   2.81\\
     NaN &    Inf &   1.42 &   1.08 &   0.87
\end{bmatrix}$$

\section{2-dimensional CTMC}
Next we considered a CTMC that jointly models the imbalance bin and the price change over a subsequent interval. That is, the CTMC modelled the joint distribution $(I(t), \Delta S(t))$ where $I(t) \in \lbrace 1,2,\dots,\#_{bins} \rbrace$ is the bin corresponding to imbalance averaged over the interval $[t-\Delta t_I, t]$, and $\Delta S(t) = \sgn(S(t+\Delta t_S)-S(t)) \in \lbrace -1, 0, 1 \rbrace$.  The pair $(I(t), \Delta S(t))$ was then reduced into one dimension with a simple encoding which we will denote $\varphi(I(t),S(t))$; for example, using 3 bins:

\begin{table}[H]
\centering
\ra{1.2}
\begin{tabular}{@{}rrrcrrrcrrr@{}}
\toprule
$Z(t)$ & Bin $I(t)$ & $\Delta S(t)$ & \phantom{abc} & $Z(t)$ & Bin $I(t)$ & $\Delta S(t)$ & \phantom{abc} & $Z(t)$ & Bin $I(t)$ & $\Delta S(t)$ \\
\cmidrule{1-3} \cmidrule{5-7} \cmidrule{9-11}
1 & Bin 1 & $<0$ && 4 & Bin 1 & $0$ && 7 & Bin 1 & $>0$ \\
2 & Bin 2 & $<0$ && 5 & Bin 2 & $0$ && 8 & Bin 2 & $>0$ \\
3 & Bin 3 & $<0$ && 6 & Bin 3 & $0$ && 9 & Bin 3 & $>0$ \\
\bottomrule
\end{tabular}
\caption{$\varphi(I(t),S(t))$: 1-Dimensional Encoding of 2-Dimensional CTMC}
\end{table}

It is crucial to note that the value $\Delta S(t)$ contains the price change from time $t$ over the \textit{future} $\Delta t_S$ seconds - hence in real-time one cannot know the state of the Markov Chain. However, the analytic results do prove enlightening: from the resulting timeseries we estimated a generator matrix $\mat{G}$, and transform it into a one-step transition probability matrix $\mat{P} = e^{\mat{G}\Delta t_I}$. The entries of $\mat{P}$ are the conditional probabilities 
\begin{align}
\mat{P}_{ij} & = \mathbb{P}\left[ \varphi( I_{[t-\Delta t_I, t]}, \Delta S_{[t,t+\Delta t_S]}) = j \; | \; \varphi( I_{[t-2\Delta t_I, t-\Delta t_I]}, \Delta S_{[t-\Delta t_I, t]} ) = i \right] \label{eq:POneStepUgly} \\
\intertext{which can be expressed semantically as}
& = \mathbb{P}\left[ \varphi( \rho_{curr}, \Delta S_{future}) = j \; | \; \varphi( \rho_{prev}, \Delta S_{curr} ) = i \right] \label{eq:POneStepNice} \\
\intertext{Since we can easily decode the 1-dimensional Markov state back into two dimensions, we can think of $\mat{P}$ as being four-dimensional and re-write its entries as}
& = \mathbb{P}\left[ \rho_{curr} = i,  \Delta S_{future} = j \; | \; \rho_{prev} = k \Delta S_{curr} = m \right] \\
& = \mathbb{P}\left[ \rho_{curr} = i,  \Delta S_{future} = j \; | \; B \right]
\end{align}
where we're using the shorthand $B = (\rho_{n-1} \in k, \Delta S_{n-1} \in m)$ to represent the states in the previous timestep. Applying Bayes' Rule:
\begin{equation}\label{eq:POneStepBayes}
\mathbb{P}\left[ \Delta S_n \in j \; | \; B, \rho_n \in i \right] = \dfrac{\mathbb{P}\left[ \rho_n \in i, \Delta S_n \in j \; | \; B \right]}{\mathbb{P}\left[ \rho_n \in i \; | \; B \right]}
\end{equation}
where the right-hand-side numerator is each individual entry of the one-step probability matrix $\mat{P}$, and the denominator can be computed from $\mat{P}$ by:
\begin{equation}\label{eq:POneStepBayesDenom}
\mathbb{P}\left[ \rho_n \in i \; | \; B \right] = \sum\limits_j \mathbb{P}\left[ \rho_n \in i,  \Delta S_n \in j \; | \; B \right]
\end{equation}
This result is of great interest to us: the left-hand-side value is the probability of seeing a given price change over the immediate future time interval conditional on past imbalances and the most recent price change, and therefore allows us to predict future price moves. We'll denote by $\mat{Q}$ the matrix containing all values given by \eqref{eq:POneStepBayes}.

The following results were obtained using data for \texttt{ORCL} from 2013-05-15, averaging imbalance timewindow $t_I = 1000\text{ms}$, $K=3$ imbalance bins, and price change timewindow $t_S = 1000\text{ms}$:

\mynote{these aren't the real results. re-run these, and format it better.}
$$\mat{G}_{Z_{bid}} =
\begin{bmatrix}
-0.9928 &   0.0217   &      0 &   0.2826  &  0.5870  &  0.0870  &       0   & 0.0145     &    0 \\

    0.0118  & -0.9647   &     0  &  0.1412 &   0.5882 &   0.2000   &      0   & 0.0118  &  0.0118 \\
         0  &  0.0909  & -1.0000   &      0  &  0.3636  &  0.5455  &       0     & 0  &       0 \\
    0.0146  &  0.0005     &    0  & -0.0792  &  0.0562   & 0.0034 &   0.0036   & 0.0006  &  0.0003 \\
    0.0016 &   0.0052   & 0.0003 &   0.0435  & -0.0897 &   0.0300  &       0   & 0.0080 &   0.0011 \\
    0.0003&    0.0025 &   0.0022  &  0.0053   & 0.0919  & -0.1277     &    0   & 0.0017 &   0.0237 \\
         0  &  0.0345   &      0  &  0.4138  &  0.4138  &  0.1034 &  -1.0000   & 0.0345    &     0 \\
    0.0179   & 0.0179    &     0   & 0.2232   & 0.5536  &  0.1250 &   0.0089  & -0.9732 &   0.0268 \\
    0.0094&    0.0189   &      0  &  0.1132&    0.5189 &  0.3113    &     0   & 0.0094 &  -0.9811
\end{bmatrix}$$

$\mat{Q}$:

$$  \begin{smallmatrix}
    \Delta S_n < 0 \rightarrow \\
    \Delta S_n = 0 \rightarrow \\
    \Delta S_n > 0 \rightarrow
  \end{smallmatrix}
  \left [
    \begin{smallmatrix}
\overmat{\rho_n = 1}{.67 & .05 & .04 & .01 & .03 & .04 & .00 & .05 & .05} & \overmat{\rho_n = 2}{.02 & .50 & .12 & .01 & .00 & .02 & .05 & .01 & .02} & 
\overmat{\rho_n = 3}{.00 & .00 & .52 & .00 & .01 & .00 & .00 & .00 & .00} \\
.33 & .95 & .96 & .99 & .97 & .96 & .41 & .93 & .95 & .96 & .49 & .87 & .98 & .99 & .97 & .91 & .48 & .96 & .98 & .95 & .47 & .95 & .96 & .93 & .98 & .88 & .34 \\ \undermat{\Delta S_{n-1} < 0}{.00 & .00 & .00} & 
\undermat{}{.00 & .00 & .00} & 
\undermat{\Delta S_{n-1} > 0}{.58 & .02 & .00} & 
\undermat{}{.02 & .01 & .00} & 
\undermat{\Delta S_{n-1} = 0}{.01 & .01 & .01} & 
\undermat{}{.05 & .51 & .01} & 
\undermat{}{.02 & .04 & .01} & 
\undermat{}{.05 & .03 & .02} & 
\undermat{}{.02 & .12 & .66}
    \end{smallmatrix}
  \right ]
$$

Immediately evident from $\mat{Q}$ is that in most cases we are expecting no price change. In fact, the only cases in which the probability of a price change is $>0.5$ show evidence of \textit{momentum}; for example, the way to interpret the value in row 1, column 1 is: if $\rho_{prev} = \rho_{curr} = 1$ and previously we saw a downward price change, then we expect to again see a downward price change. In fact, the best way to summarize the matrix is:
\begin{equation}\label{eq:EDAKeyInsight}
\mathbb{P} \left[ \Delta S_{curr} = \Delta S_{prev} \; | \; \rho_{prev} = \rho_{curr} \right] > 0.5
\end{equation} 

\section{In-Sample Backtesting of Naive Trading Strategies}
Utilizing the key insight drawn from \eqref{eq:EDAKeyInsight}, we backtested a number of naive trading strategies, descriptions of which follow:

\subsection{Naive Trading Strategy}  Using the conditional probabilities obtained from $\mat{P_C}$, we will execute a buy (resp. sell) market order if the probability of an upward (resp. downward) price change is $> 0.5$.

\begin{algorithm}[H]
\caption{Naive Trading Strategy}
\begin{algorithmic}[1]
\State $cash = 0$
\State $asset = 0$
\For{$t=2 \; : \; \texttt{length}(timeseries)$}
	\If {$\mathbb{P} \left[ \Delta S_{curr} < 0 \; | \; \rho_{curr}, \rho_{prev}, \Delta S_{prev} \right] > 0.5$}
		\State $cash \pluseq data.BuyPrice(\textit{t})$
		\State $asset \mineq 1$
	\ElsIf {$\mathbb{P} \left[ \Delta S_{curr} > 0 \; | \; \rho_{curr}, \rho_{prev}, \Delta S_{prev} \right] > 0.5$}
		\State $cash \mineq data.SellPrice(\textit{t})$	
		\State $asset \pluseq 1$
	\EndIf
\EndFor
\If {$asset > 0$} 
	\State $cash \pluseq asset \times data.BuyPrice(\textit{t})$
\ElsIf {$asset < 0$} 
	\State $cash \pluseq asset \times data.SellPrice(\textit{t})$	
\EndIf
\end{algorithmic}
\end{algorithm}

\subsection{Naive+ Trading Strategy} Extending the naive trading strategy, if we anticipate no change then we'll additionally keep limited orders posted at the touch, front of the queue. We'll track MO arrival, assume we always get executed, and immediately repost the limit orders.

\begin{algorithm}[H]
\caption{Naive+ Trading Strategy}
\begin{algorithmic}[1]
\State $cash = 0$
\State $asset = 0$
\State $LO_{posted} = \texttt{False}$
\For{$t=2 \; : \; \texttt{length}(timeseries)$}
	\If {$\mathbb{P} \left[ \Delta S_{curr} < 0 \; | \; \rho_{curr}, \rho_{prev}, \Delta S_{prev} \right] > 0.5$}
		\State $cash \pluseq data.BuyPrice(\textit{t})$
		\State $asset \mineq 1$
		\State $LO_{posted} = \texttt{False}$
	\ElsIf {$\mathbb{P} \left[ \Delta S_{curr} > 0 \; | \; \rho_{curr}, \rho_{prev}, \Delta S_{prev} \right] > 0.5$}
		\State $cash \mineq data.SellPrice(\textit{t})$	
		\State $asset \pluseq 1$
		\State $LO_{posted} = \texttt{False}$
	\ElsIf {$\mathbb{P} \left[ \Delta S_{curr} = 0 \; | \; \rho_{curr}, \rho_{prev}, \Delta S_{prev} \right] > 0.5$}
		\State $LO_{posted} = \texttt{True}$
	\EndIf
	\If {$LO_{posted}$}
		\For{$MO \in ArrivedMarketOrders(t,t+1)$}		
			\If {$MO == Sell$}
				\State $cash \mineq data.BuyPrice(\textit{t})$	
				\State $asset \pluseq 1$
			\ElsIf {$MO == Buy$}
				\State $cash \pluseq data.SellPrice(\textit{t})$
				\State $asset \mineq 1$
			\EndIf
		\EndFor
	\EndIf
\EndFor
\If {$asset > 0$} 
\State $cash \pluseq asset \times data.BuyPrice(\textit{t})$
\ElsIf {$asset < 0$} 
\State $cash \pluseq asset \times data.SellPrice(\textit{t})$	
\EndIf
\end{algorithmic}
\end{algorithm}

\subsection{Naive++ Trading Strategy} We won't execute market orders or keep limit orders at the touch. Using the conditional probabilities obtained from $\mat{P_C}$, if we expect a downward (resp. upward) price change then we'll add a limit order to the sell (resp. buy) side, and hopefully pick up an agent who is executing a market order going against the price change momentum. 

\begin{algorithm}[H]
\caption{Naive++ Trading Strategy}
\begin{algorithmic}[1]
\State $cash = 0$
\State $asset = 0$
\State $LOBuy_{posted} = \texttt{False}$
\State $LOSell_{posted} = \texttt{False}$
\For{$t=2 \; : \; \texttt{length}(timeseries)$}
	\If {$\mathbb{P} \left[ \Delta S_{curr} < 0 \; | \; \rho_{curr}, \rho_{prev}, \Delta S_{prev} \right] > 0.5$}
		\State $LOBuy_{posted} = \texttt{False}$
		\State $LOSell_{posted} = \texttt{True}$
	\ElsIf {$\mathbb{P} \left[ \Delta S_{curr} > 0 \; | \; \rho_{curr}, \rho_{prev}, \Delta S_{prev} \right] > 0.5$}
		\State $LOBuy_{posted} = \texttt{True}$
		\State $LOSell_{posted} = \texttt{False}$
	\ElsIf {$\mathbb{P} \left[ \Delta S_{curr} = 0 \; | \; \rho_{curr}, \rho_{prev}, \Delta S_{prev} \right] > 0.5$}
		\State $LOBuy_{posted} = \texttt{False}$
		\State $LOSell_{posted} = \texttt{False}$
	\EndIf

	\For{$MO \in ArrivedMarketOrders(t,t+1)$}		
		\If {$MO == Sell \; \land \; LOBuy_{posted}$}
			\State $cash \mineq data.BuyPrice(\textit{t})$	
			\State $asset \pluseq 1$
		\ElsIf {$MO == Buy \; \land \; LOSell_{posted}$}
			\State $cash \pluseq data.SellPrice(\textit{t})$
			\State $asset \mineq 1$
		\EndIf
	\EndFor
\EndFor
\If {$asset > 0$} 
\State $cash \pluseq asset \times data.BuyPrice(\textit{t})$
\ElsIf {$asset < 0$} 
\State $cash \pluseq asset \times data.SellPrice(\textit{t})$	
\EndIf
\end{algorithmic}
\end{algorithm}

\paragraph{Naive- Trading Strategy} We additionally considered a trading strategy, for benchmark purposes, which used only current imbalance to predict future price change. But actually this predicted $\mathbb{P} \left[ \Delta S_{curr} = 0 \right] > 0.5$ at all times, so we could not run a strategy off it.

Backtesting these trading strategies required a choice of parameters for $\Delta t_S$, the price change observation period, $\Delta t_I$, the imbalance averaging period, and $\#_{bins}$, the number of imbalance bins. Through a brute force calibration technique we found that $\#_{bins} = 4$ provided the highest expected number of successful trades for most tickers, so this was chosen as a constant. Similarly, we empirically saw that calibration always yielded $\Delta t_S = \Delta t_I$, so this was taken as a given. Then each backtest consisted of first calibrating the value $\Delta t_I$ from one day of data by maximizing the intra-day Sharpe ratio, then using the calibrated parameters to backtest the entire year.

\begin{figure}
  \includegraphics[width=\textwidth]{Figs/fig-INTC-year-bookvals}
  \caption{INTC: Book value against time of trading day.}
\end{figure}

\begin{figure}
  \includegraphics[width=\textwidth]{Figs/fig-INTC-15min-hist}
  \caption{INTC: Histogram of 15min book value changes.}
\end{figure}

\begin{figure}
  \centering
  \setlength\figureheight{.5\linewidth} 
  \setlength\figurewidth{.5\linewidth}
  \input{/home/anton/Documents/masc/ml/matlab/sta4505/fig126a.tikz}
  \caption{Optimal posting depth $\delta$}
  \label{fig:126a}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{.35\linewidth}
  \centering
  \setlength\figureheight{\linewidth} 
  \setlength\figurewidth{\linewidth}
  \input{Figs/FARO-strategy-compare.tikz}
  \caption{FARO}
\end{subfigure}%
\hfil%
\begin{subfigure}{.35\linewidth}
  \centering
  \setlength\figureheight{\linewidth}
  \setlength\figurewidth{\linewidth}
  \input{Figs/NTAP-strategy-compare.tikz} 
  \caption{NTAP}
\end{subfigure}\\
\vspace{1cm}
\begin{subfigure}{.35\linewidth}
  \centering
  \setlength\figureheight{\linewidth} 
  \setlength\figurewidth{\linewidth}
  \input{Figs/ORCL-strategy-compare.tikz}
  \caption{ORCL}
\end{subfigure}%
\hfil%
\begin{subfigure}{.35\linewidth}
  \centering
  \setlength\figureheight{\linewidth}
  \setlength\figurewidth{\linewidth}
  \input{Figs/ORCL-strategy-compare.tikz} 
  \caption{AAPL}
\end{subfigure}%
  \caption{Comparison of Naive (red), Naive+ (blue), and Naive++ (green) trading strategies, with benchmark Midprice (black). Plotted are book values against time of trading day, averaged across trading year.}
  \label{fig:comp}
\end{figure}

\section{Conclusions from Naive Trading Strategies}

To properly compare the Naive trading strategies, it must be understood that the Naive+ strategy has the Naive built into it - thus it's actually the difference between the two that needs to be assessed to ascertain the effect of posting Limit Orders when no price change is predicted. As seen in Figure \ref{fig:comp}, the Naive trading strategy on average underperformed the average mid price, while the Naive+ (adding at-the-touch limit orders when no change was predicted) and Naive++ (adding limit orders to adversely selecting agents that traded against the price change momentum) strategies both on average generated revenue. 

\paragraph{Question 1} Why is the Naive strategy producing, on average, normalized losses? Especially so when considering that we are \underline{in-sample backtesting}. On calibration, we see that our intra-day Sharpe ratio is around 0.01 or 0.02 when we choose our optimal parameters, so at the very least on the calibration date the strategy produces positive returns. The remainder of the calendar days are out-of-sample, as the parameters are (likely) not optimal. This suggests non-stationary data, and in particular not every day can be modelled by the same Markov chain. The problem may be exaggerated by the fact that we're calibrating on the first trading day of the calendar year, when we might expect reduced, or at least non-representative, trading activity. Further, we're currently obtaining the $\mat{P_C}$ probability matrix using only bid-side data, not sell-side or mid, and we're ignoring the bid-ask spread. Thus predicting a ``price change'' may be insufficient when considering a monetizable opportunity, as we won't be able to profit off a predicted increase followed by a predicted decrease unless the interim mid-price move is greater than the bid-ask spread (assuming constant spread). This suggests a potential straightforward modification to the strategy.

\paragraph{Question 2} Why do the Naive+ and ++ strategies outperform the Naive strategy? This is particularly interesting since the probabilities are being obtained from the same matrix. The obvious difference between the successful and unsuccessful strategies is that the former (a) uses limit orders, and (b) executes when we predict a zero change, whereas the latter uses (a) market orders, and (b) executes when we do predict non-zero change.

(a) obviously leads to a different transaction price being used: if I buy with a LO I'm paying the bid price, whereas buying with a MO I pay the ask price. If I value the stock using the mid price, and the mid price doesn't move as a result of my transaction, then with LO I'm buying the asset for less than I'm valuing it at, and with MO I'm paying more than its value.

(b) seems to be the largest flaw in the Naive strategy, to which there are two factors. One, we are not predicting the magnitude of the price change, only whether it is zero or non-zero. Two, from the probabilities presented above, \textit{we will only predict a price change if we've already seen a price change}. Thus we're effectively reacting too late. 

Here's how this works adversely. Suppose a stock has bid/ask quotes of \$9.99/\$10.01, for a bid-ask spread of \$0.02 and a mid of \$10.

\begin{enumerate}
\item Imbalance = 1 (pressure for upward price move). [$NPV = 0$]
\item Bid/ask goes up to \$10.00/\$10.02. [$NPV = 0$]
\item Imbalance = 1. We predict another $>0$ price change. [$NPV = 0$]
\item We buy 1 share (at \$10.02). [$NPV = -0.01$]
\item Bid/ask goes up to \$10.01/\$10.03. [$NPV = 0$]
\item Imbalance = -1 (pressure for a downward move). [$NPV = 0$]
\item Bid/ask goes down to \$10.00/\$10.02. [$NPV = -0.01$]
\item Imbalance = -1. We predict another $<0$ price change. 
\item We sell 1 share (at \$10.00). [$NPV = -0.02$]
\item Bid/ask goes down to \$9.99/\$10.01. [$NPV = -0.02$]
\end{enumerate}

In this example the price goes up and back down by two cents to return to where it started, and in the process we lost \$0.02. Now imagine what happens if we price goes up by one cent, up by one cent, then down by ten cents, down by one cent. In this case we lose \$0.11. We're unable to predict that initial upward or downward price change, and only react to it. 