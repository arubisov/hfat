\chapter{Introduction}

Algorithmic trading is the process of running computer algorithms to execute orders on an electronic exchange such as NASDAQ. Speed of execution is typically paramount (and hence the alternate moniker of high-frequency trading), often requiring running the algorithms on servers directly wired to the exchange (known as co-location). Theoretically, high-frequency trading is encompassed by algorithmic trading, but not all algorithmic trading need be high-frequency; however, the two terms are often used interchangeably. 

High-frequency trading can be proprietary or non-proprietary, and varies greatly across the different types of strategies employed. For example, low-latency strategies utilize naive algorithms to profit from price discrepancies for a single stock cross-listed on multiple exchanges, while statistical arbitrage strategies use complex algorithms to profit from observed statistical patterns of a single stock on a single exchange.

Proprietary trading refers to trading for-profit with an institution's money, e.g. the livelihood of hedge funds. Cross-exchange arbitrage uses primitive algorithms and emphasizes speed: the server is co-located at one of the exchanges, algorithm latency is on the order of microseconds, and the limiting reagent is the time taken for information to travel to and from the other exchange. In the case of Chicago and New York, for example, information can make the trip in 6ms via fibreoptics that send information at half the speed of light. For this reason, agents are now paying for access to a system of ground satellites that has been set up to relay information between the two exchanges via microwaves, shaving latency down to 4ms \citep{Laughlin14}.

Non-proprietary algorithmic trading is generally aimed at transaction cost reduction, with the primary theoretical paper on the subject being \citet{Bertsimas98} and \citet{Almgren01}. When an institutional investor wishes to buy or sell a large quantity of shares, the aim of the trader is to obtain the best possible price compared with some benchmark (often taken to be the midprice at the time of initiating the strategy). Here the definition of `large' is determined relative to the liquidity of the stock - either in comparison to the average size of trades for the given stock, or to the available quantity to be bought/sold at the best listed price. The goal of the algorithmic trading is then to split up the large order into smaller pieces and execute them on an algorithmically-determined schedule, balancing the total time for execution with the volatility of the price the trader will receive. 

In statistical arbitrage, the aim is to exploit predictable statistical patterns in the available data provided by the exchange, e.g. predicting stock price movements from prices observed thus far. This method too requires co-location, and operates on the scale of milliseconds. It is this type of high-frequency trading that I will explore in this dissertation. 

As part of the Dodd-Frank Act of 2010, the Volcker Rule has banned US banks from making certain speculative investments, and in so doing effectively curbed their proprietary trading activity. Nevertheless, as they are still required to provide liquidity to markets via market-making, banks utilize algorithmic trading to determine the bid/ask bands they will send to exchanges. Thus it remains feasible for banks to simply shift the bands they send in order to comply with market-making requirements and simultaneously execute a given strategy.

\section{Limit Order Book Dynamics}

A \emph{limit order} is an instruction submitted by an agent to buy or sell up to a specified quantity or volume of a financial instrument, and at a specified price. A \emph{limit order book (LOB)} is the accumulated list of such orders sent to a given exchange, where each order is accompanied by a timestamp and an anonymous unique key for identifying the agent. The exchange runs a trade matching engine that utilizes the LOB to pair buy and sell requests that concur on price, even if only partially on volume. Orders remain in effect until they are modified, canceled, or fully filled \citep{Kyle1989}.

The unfilled or partially filled orders accumulate in the limit order book and provide liquidity to the market. At any given time, the structure of the LOB can be visualized as in \autoref{fig:LOB}. As new limit orders arrive, they are compared with existing opposing orders in the book in search of a match - and if so, existing orders are \emph{filled} or \emph{lifted} according to a first-in-first-out priority queue for each price level. \emph{Market orders} extend the idea of limit orders by specifying only the volume, and accept the best possible price currently available in the LOB; whereas limit orders are free to post, modify, and cancel (as an incentive for providing liquidity), market orders are charged a fee.

\begin{figure}
  \tikzsetnextfilename{LOB}
  \input{Figs/LOB.tikz}
%  \includegraphics[width=0.9\textwidth]{Figs/LOBAshBooth.png}
\caption{Structure and mechanics of the limit order book, adapted from \citet{Booth15}. Each block represents an order, of varying volumes, submitted by an agent.}
\label{fig:LOB}
\end{figure}

In the literature, LOBs are generally modelled in one of two ways: either by an economics-based approach, or a physics-based approach \citep{Summary2013}. The economics based approaches are trader-centric, assume perfect rationality, view order flow as static, and seek to understand trader strategies, in particular through game-style theories. By contrast, the physics approach, with which we are more concerned here, assumes zero-intelligence, provides conceptual toy models of the evolution of the book, and is concerned with the search for statistical regularity. The dynamics of the book, namely order arrivals and cancellations, are governed by stochastic processes of varying complexity, from particles on a 1-D price lattice \citep{Bak97} to independent Poisson processes governing the arrival, modification, and cancellation of orders \citep{Cont10}. See \citet{Summary2013} for an excellent literature survey on LOB modelling.

In this thesis, I will be concerned primarily with limit order book order imbalance. \emph{Imbalance} is a ratio of limit order volumes between the bid and ask side, and in this work is calculated as 
\begin{equation}\label{eq:LOBImbalance}
I(t) = \dfrac{V_{bid}(t) - V_{ask}(t)}{V_{bid}(t) + V_{ask}(t)} \in [-1,1]
\end{equation}
where both $V_{bid}$ and $V_{ask}$ are computed as the weighted average volumes at the best three prices, with exponentially decreasing weights.

\section{ITCH Data Set}
\fxnote{write ITCH data set section.}